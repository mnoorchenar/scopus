% Section: Introduction
@article{childers2018understanding,
  title={Understanding costs of care in the operating room},
  author={Childers, Christopher P and Maggard-Gibbons, Melinda},
  journal={JAMA surgery},
  volume={153},
  number={4},
  pages={e176233--e176233},
  year={2018},
  publisher={American Medical Association}
}

@article{smith2022creating,
  title={Creating a practical transformational change management model for novel artificial intelligence--enabled technology implementation in the operating room},
  author={Smith, Tianqi G and Norasi, Hamid and Herbst, Kelly M and Kendrick, Michael L and Curry, Timothy B and Grantcharov, Teodor P and Palter, Vanessa N and Hallbeck, M Susan and Cleary, Sean P},
  journal={Mayo Clinic Proceedings: Innovations, Quality \& Outcomes},
  volume={6},
  number={6},
  pages={584--596},
  year={2022},
  publisher={Elsevier}
}

@article{brailsford2011or,
  title={OR in healthcare: A European perspective},
  author={Brailsford, Sally and Vissers, Jan},
  journal={European journal of operational research},
  volume={212},
  number={2},
  pages={223--234},
  year={2011},
  publisher={Elsevier}
}

@article{martinez2021machine,
  title={Machine learning for surgical time prediction},
  author={Martinez, Oscar and Martinez, Carol and Parra, Carlos A and Rugeles, Saul and Suarez, Daniel R},
  journal={Computer Methods and Programs in Biomedicine},
  volume={208},
  pages={106220},
  year={2021},
  publisher={Elsevier}
}

@article{zhu2019operating,
  title={Operating room planning and surgical case scheduling: a review of literature},
  author={Zhu, Shuwan and Fan, Wenjuan and Yang, Shanlin and Pei, Jun and Pardalos, Panos M},
  journal={Journal of Combinatorial Optimization},
  volume={37},
  pages={757--805},
  year={2019},
  publisher={Springer}
}

@article{snyder2019big,
  title={Big data and health},
  author={Snyder, Michael and Zhou, Wenyu},
  journal={The Lancet Digital Health},
  volume={1},
  number={6},
  pages={e252--e254},
  year={2019},
  publisher={Elsevier}
}

@article{bellini2024artificial,
  title={Artificial intelligence in operating room management},
  author={Bellini, Valentina and Russo, Michele and Domenichetti, Tania and Panizzi, Matteo and Allai, Simone and Bignami, Elena Giovanna},
  journal={Journal of medical systems},
  volume={48},
  number={1},
  pages={19},
  year={2024},
  publisher={Springer}
}

@article{birkhoff2021review,
  title={A review on the current applications of artificial intelligence in the operating room},
  author={Birkhoff, David C and van Dalen, Anne Sophie HM and Schijven, Marlies P},
  journal={Surgical Innovation},
  volume={28},
  number={5},
  pages={611--619},
  year={2021},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{goh2021artificial,
  title={Artificial intelligence in sepsis early prediction and diagnosis using unstructured data in healthcare},
  author={Goh, Kim Huat and Wang, Le and Yeow, Adrian Yong Kwang and Poh, Hermione and Li, Ke and Yeow, Joannas Jie Lin and Tan, Gamaliel Yu Heng},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={711},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{chen2020extracting,
  title={Extracting medication information from unstructured public health data: a demonstration on data from population-based and tertiary-based samples},
  author={Chen, Robert and Ho, Joyce C and Lin, Jin-Mann S},
  journal={BMC Medical Research Methodology},
  volume={20},
  pages={1--11},
  year={2020},
  publisher={Springer}
}

@article{alsentzer2019publicly,
  title={Publicly available clinical BERT embeddings},
  author={Alsentzer, Emily and Murphy, John R and Boag, Willie and Weng, Wei-Hung and Jin, Di and Naumann, Tristan and McDermott, Matthew},
  journal={arXiv preprint arXiv:1904.03323},
  year={2019}
}

@article{reimers2019sentence,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

% Section: Related Work
@ARTICLE{Bartek2019346,
	author = {Bartek, Matthew A. and Saxena, Rajeev C. and Solomon, Stuart and Fong, Christine T. and Behara, Lakshmana D. and Venigandla, Ravitheja and Velagapudi, Kalyani and Lang, John D. and Nair, Bala G.},
	title = {Improving Operating Room Efficiency: Machine Learning Approach to Predict Case-Time Duration},
	year = {2019},
	journal = {Journal of the American College of Surgeons},
	volume = {229},
	number = {4},
	pages = {346 – 354.e3},
	doi = {10.1016/j.jamcollsurg.2019.05.029},
	abstract = {Background: Accurate estimation of operative case-time duration is critical for optimizing operating room use. Current estimates are inaccurate and earlier models include data not available at the time of scheduling. Our objective was to develop statistical models in a large retrospective data set to improve estimation of case-time duration relative to current standards. Study Design: We developed models to predict case-time duration using linear regression and supervised machine learning. For each of these models, we generated an all-inclusive model, service-specific models, and surgeon-specific models. In the latter 2 approaches, individual models were created for each surgical service and surgeon, respectively. Our data set included 46,986 scheduled operations performed at a large academic medical center from January 2014 to December 2017, with 80% used for training and 20% for model testing/validation. Predictions derived from each model were compared with our institutional standard of using average historic procedure times and surgeon estimates. Models were evaluated based on accuracy, overage (case duration > predicted + 10%), underage (case duration < predicted – 10%), and the predictive capability of being within a 10% tolerance threshold. Results: The machine learning algorithm resulted in the highest predictive capability. The surgeon-specific model was superior to the service-specific model, with higher accuracy, lower percentage of overage and underage, and higher percentage of cases within the 10% threshold. The ability to predict cases within 10% improved from 32% using our institutional standard to 39% with the machine learning surgeon-specific model. Conclusions: Our study is a notable advancement toward statistical modeling of case-time duration across all surgical departments in a large tertiary medical center. Machine learning approaches can improve case duration estimations, enabling improved operating room scheduling, efficiency, and reduced costs. © 2019},
	publisher = {Elsevier Inc.},
	type = {Conference paper},
	note = {Cited by: 100}
}

@ARTICLE{Martinez2021,
	author = {Martinez, Oscar and Martinez, Carol and Parra, Carlos A. and Rugeles, Saul and Suarez, Daniel R.},
	title = {Machine learning for surgical time prediction},
	year = {2021},
	journal = {Computer Methods and Programs in Biomedicine},
	volume = {208},
	doi = {10.1016/j.cmpb.2021.106220},
	abstract = {Background and Objective: Operating Rooms (ORs) are among the most expensive services in hospitals. A challenge to optimize the OR efficiency is to improve the surgery scheduling task, which requires the estimation of surgical time duration. Surgeons or programming units (based on people's experience) typically do the duration estimation using an experience-based strategy, which may include some bias, such as overestimating the surgery time, increasing ORs' operational cost. Methods: This paper analyzes a machine learning-based solution for surgical time predictions. We apply and compare four machine-learning algorithms (Linear Regression, Support Vector Machines, Regression Trees, and Bagged Trees) to predict the surgical time duration at a tertiary referral university hospital in Bogotá, Colombia. Historical data from 2004 until 2019 was used to train the algorithms. Comparison among algorithms was given in terms of the Root Mean Square Error (RMSE) of the predicted surgery duration and the algorithms' computing time. The algorithm with the best performance was compared to the currently used experience-based method. Results: All the ML algorithms predict the surgery duration with an error between 26 and 37 min. The best overall performance was obtained using Bagged Trees (26 min RMSE, 3.16 min training time, 0.49 min testing time) when using a subset of the DB with the nine specialties containing 80% of the surgeries. Bagged Trees also outperformed the experience-based method with a lower RMSE; however, it also shifted from a predominant overestimation to underestimating surgeries' duration. Conclusions: Different ML algorithms for predicting the surgical time duration, showing and comparing their performance. Bagged Trees showed the best performance in terms of RMSE and computing time. Depending on the initial data, Bagged Trees outperformed the experience-based method, but future work is necessary to suit it, like any other ML algorithm, to the hospitals' needs. © 2021},
	publisher = {Elsevier Ireland Ltd},
	type = {Article},
	note = {Cited by: 42}
}

@ARTICLE{Park2025,
	author = {Park, Jung-Bin and Roh, Gyun-Ho and Kim, Kwangsoo and Kim, Hee-Soo},
	title = {Development of Predictive Model of Surgical Case Durations Using Machine Learning Approach},
	year = {2025},
	journal = {Journal of Medical Systems},
	volume = {49},
	number = {1},
	doi = {10.1007/s10916-025-02141-y},
	abstract = {Optimizing operating room (OR) utilization is critical for enhancing hospital management and operational efficiency. Accurate surgical case duration predictions are essential for achieving this optimization. Our study aimed to refine the accuracy of these predictions beyond traditional estimation methods by developing Random Forest models tailored to specific surgical departments. Utilizing a comprehensive dataset, we applied several machine learning algorithms, including RandomForest, XGBoost, Linear Regression, LightGBM, and CatBoost, and assessed their performance using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R-Squared (R2) metrics. Our findings highlighted that Random Forest models excelled in department-specific applications, achieving an MAE of 16.32, an RMSE of 31.19, and an R2 of 0.92, significantly outperforming general models and conventional estimates. This improvement emphasizes the advantage of customizing models to fit the distinct characteristics and data patterns of each department. Additionally, our SHAP-based feature importance analysis identified morning operation timing, ICU ward assignments, operation codes, and surgeon IDs as key factors influencing surgical duration. This suggests that a detailed and nuanced approach to model development can substantially increase prediction accuracy. By providing a more accurate, reliable tool for predicting surgical case durations, our department-specific Random Forest models promise to enhance surgical scheduling, leading to more effective OR management. This approach underscores the importance of leveraging tailored, data-driven models to improve healthcare outcomes and operational efficiency. © The Author(s) 2025.},
	publisher = {Springer},
	type = {Article},
	note = {Cited by: 1}
}

@ARTICLE{Miller2023241,
	author = {Miller, Lauren E. and Goedicke, William and Crowson, Matthew G. and Rathi, Vinay K. and Naunheim, Matthew R. and Agarwala, Aalok V.},
	title = {Using Machine Learning to Predict Operating Room Case Duration: A Case Study in Otolaryngology},
	year = {2023},
	journal = {Otolaryngology - Head and Neck Surgery (United States)},
	volume = {168},
	number = {2},
	pages = {241 – 247},
	doi = {10.1177/01945998221076480},
	abstract = {Objective: Optimizing operating room (OR) efficiency depends on accurate case duration estimates. Machine learning (ML) methods have been used to predict OR case durations in other subspecialties. We hypothesize that ML methods improve projected case lengths over existing non-ML techniques for otolaryngology–head and neck surgery cases. Methods: Deidentified patient information from otolaryngology surgical cases at 1 academic institution were reviewed from 2016 to 2020. Variables collected included patient, surgeon, procedure, and facility data known preoperatively so as to capture all realistic contributors. Available case data were divided into a training and testing data set. Several ML algorithms were evaluated based on best performance of predicted case duration when compared to actual case duration. Performance of all models was compared by the average root mean squared error and mean absolute error (MAE). Results: In total, 50,888 otolaryngology surgical cases were evaluated with an average case duration of 98.3 ± 86.9 minutes. Most cases were general otolaryngology (n = 16,620). Case features closely associated with OR duration included procedure performed, surgeon, subspecialty of case, and postoperative destination of the patient. The best-performing ML models were CatBoost and XGBoost, which reduced operative time MAE by 9.6 minutes and 8.5 minutes compared to current methods, respectively. Discussion: The incorporation of other easily identifiable features beyond procedure performed and surgeon meaningfully improved our operative duration prediction accuracy. CatBoost provided the best-performing ML model. Implications for Practice: ML algorithms to predict OR case time duration in otolaryngology can improve case duration accuracy and result in financial benefit. © 2023 American Academy of Otolaryngology–Head and Neck Surgery Foundation.},
	publisher = {John Wiley and Sons Inc},
	type = {Article},
	note = {Cited by: 14}
}

@ARTICLE{Yeo20233299,
	author = {Yeo, Ingwon and Klemt, Christian and Melnic, Christopher M. and Pattavina, Meghan H. and De Oliveira, Bruna M. Castro and Kwon, Young-Min},
	title = {Predicting surgical operative time in primary total knee arthroplasty utilizing machine learning models},
	year = {2023},
	journal = {Archives of Orthopaedic and Trauma Surgery},
	volume = {143},
	number = {6},
	pages = {3299 – 3307},
	doi = {10.1007/s00402-022-04588-x},
	abstract = {Background: Prolonged surgical operative time is associated with postoperative adverse outcomes following total knee arthroplasty (TKA). Increasing operating room efficiency necessitates the accurate prediction of surgical operative time for each patient. One potential way to increase the accuracy of predictions is to use advanced predictive analytics, such as machine learning. The aim of this study is to use machine learning to develop an accurate predictive model for surgical operative time for patients undergoing primary total knee arthroplasty. Methods: A retrospective chart review of electronic medical records was conducted to identify patients who underwent primary total knee arthroplasty at a tertiary referral center. Three machine learning algorithms were developed to predict surgical operative time and were assessed by discrimination, calibration and decision curve analysis. Specifically, we used: (1) Artificial Neural Networks (ANNs), (2) Random Forest (RF), and (3) K-Nearest Neighbor (KNN). Results: We analyzed the surgical operative time for 10,021 consecutive patients who underwent primary total knee arthroplasty. The neural network model achieved the best performance across discrimination (AUC = 0.82), calibration and decision curve analysis for predicting surgical operative time. Based on this algorithm, younger age (< 45 years), tranexamic acid non-usage, and a high BMI (> 40 kg/m2) were the strongest predictors associated with surgical operative time. Conclusions: This study shows excellent performance of machine learning models for predicting surgical operative time in primary total knee arthroplasty. The accurate estimation of surgical duration is important in enhancing OR efficiency and identifying patients at risk for prolonged surgical operative time. Level of evidence: Level III, case control retrospective analysis. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	type = {Article},
	note = {Cited by: 17}
}

@ARTICLE{Zaribafzadeh2023890,
	author = {Zaribafzadeh, Hamed and Webster, Wendy L. and Vail, Christopher J. and Daigle, Thomas and Kirk, Allan D. and Allen, Peter J. and Henao, Ricardo and Buckland, Daniel M.},
	title = {Development, Deployment, and Implementation of a Machine Learning Surgical Case Length Prediction Model and Prospective Evaluation},
	year = {2023},
	journal = {Annals of Surgery},
	volume = {278},
	number = {6},
	pages = {890 – 895},
	doi = {10.1097/SLA.0000000000005936},
	abstract = {Objective: To implement a machine learning model using only the restricted data available at case creation time to predict surgical case length for multiple services at different locations. Background: The operating room is one of the most expensive resources in a health system, estimated to cost $22 to $133 per minute and generate about 40% of hospital revenue. Accurate prediction of surgical case length is necessary for efficient scheduling and cost-effective utilization of the operating room and other resources. Methods: We introduced a similarity cascade to capture the complexity of cases and surgeon influence on the case length and incorporated that into a gradient-boosting machine learning model. The model loss function was customized to improve the balance between over- and under-prediction of the case length. A production pipeline was created to seamlessly deploy and implement the model across our institution. Results: The prospective analysis showed that the model output was gradually adopted by the schedulers and outperformed the scheduler-predicted case length from August to December 2022. In 33,815 surgical cases across outpatient and inpatient platforms, the operational implementation predicted 11.2% fewer underpredicted cases and 5.9% more cases within 20% of the actual case length compared with the schedulers and only overpredicted 5.3% more. The model assisted schedulers to predict 3.4% more cases within 20% of the actual case length and 4.3% fewer underpredicted cases. Conclusions: We created a unique framework that is being leveraged every day to predict surgical case length more accurately at case posting time and could be potentially utilized to deploy future machine learning models. © 2023 Lippincott Williams and Wilkins. All rights reserved.},
	publisher = {Wolters Kluwer Health},
	type = {Article},
	note = {Cited by: 6}
}

@ARTICLE{Tuwatananurak2019,
	author = {Tuwatananurak, Justin P. and Zadeh, Shayan and Xu, Xinling and Vacanti, Joshua A. and Fulton, William R. and Ehrenfeld, Jesse M. and Urman, Richard D.},
	title = {Machine Learning Can Improve Estimation of Surgical Case Duration: A Pilot Study},
	year = {2019},
	journal = {Journal of Medical Systems},
	volume = {43},
	number = {3},
	doi = {10.1007/s10916-019-1160-5},
	abstract = {Operating room (OR) utilization is a significant determinant of hospital profitability. One aspect of this is surgical scheduling, which depends on accurate predictions of case duration. This has been done historically by either the surgeon based on personal experience, or by an electronic health record (EHR) based on averaged historical means for case duration. Here, we compare the predicted case duration (pCD) accuracy of a novel machine-learning algorithm over a 3-month period. A proprietary machine learning algorithm was applied utilizing operating room factors such as patient demographic data, pre-surgical milestones, and hospital logistics and compared to that of a conventional EHR. Actual case duration and pCD (Leap Rail vs EHR) was obtained at one institution over the span of 3 months. Actual case duration was defined as time between patient entry into an OR and time of exit. pCD was defined as case time allotted by either Leap Rail or EHR. Cases where Leap Rail was unable to generate a pCD were excluded. A total of 1059 surgical cases were performed during the study period, with 990 cases being eligible for the study. Over all sub-specialties, Leap Rail showed a 7 min improvement in absolute difference between pCD and actual case duration when compared to conventional EHR (p < 0.0001). In aggregate, the Leap Rail method resulted in a 70% reduction in overall scheduling inaccuracy. Machine-learning algorithms are a promising method of increasing pCD accuracy and represent one means of improving OR planning and efficiency. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.},
	publisher = {Springer New York LLC},
	type = {Article},
	note = {Cited by: 58}
}

@article{kwong2025optimizing,
  title={Optimizing surgical efficiency: predicting case duration of common general surgery procedures using machine learning},
  author={Kwong, Michelle and Noorchenarboo, Mohammad and Grolinger, Katarina and Hawel, Jeff and Schlachta, Christopher M and Elnahas, Ahmad},
  journal={Surgical Endoscopy},
  pages={1--8},
  year={2025},
  publisher={Springer}
}

@ARTICLE{Strömblad2021315,
	author = {Strömblad, Christopher T. and Baxter-King, Ryan G. and Meisami, Amirhossein and Yee, Shok-Jean and Levine, Marcia R. and Ostrovsky, Aaron and Stein, Daniel and Iasonos, Alexia and Weiser, Martin R. and Garcia-Aguilar, Julio and Abu-Rustum, Nadeem R. and Wilson, Roger S.},
	title = {Effect of a Predictive Model on Planned Surgical Duration Accuracy, Patient Wait Time, and Use of Presurgical Resources: A Randomized Clinical Trial},
	year = {2021},
	journal = {JAMA Surgery},
	volume = {156},
	number = {4},
	pages = {315 – 321},
	doi = {10.1001/jamasurg.2020.6361},
	abstract = {Importance: Accurate surgical scheduling affects patients, clinical staff, and use of physical resources. Although numerous retrospective analyses have suggested a potential for improvement, the real-world outcome of implementing a machine learning model to predict surgical case duration appears not to have been studied. Objectives: To assess accuracy and real-world outcome from implementation of a machine learning model that predicts surgical case duration. Design, Setting, and Participants: This randomized clinical trial was conducted on 2 surgical campuses of a cancer specialty center. Patients undergoing colorectal and gynecology surgery at Memorial Sloan Kettering Cancer Center who were scheduled more than 1 day before surgery between April 7, 2018, and June 25, 2018, were included. The randomization process included 29 strata (11 gynecological surgeons at 2 campuses and 7 colorectal surgeons at a single campus) to ensure equal chance of selection for each surgeon and each campus. Patients undergoing more than 1 surgery during the study's timeframe were enrolled only once. Data analyses took place from July 2018 to November 2018. Interventions: Cases were assigned to machine learning-assisted surgical predictions 1 day before surgery and compared with a control group. Main Outcomes and Measures: The primary outcome measure was accurate prediction of the duration of each scheduled surgery, measured by (arithmetic) mean (SD) error and mean absolute error. Effects on patients and systems were measured by start time delay of following cases, the time between cases, and the time patients spent in presurgical area. Results: A total of 683 patients were included (mean [SD] age, 55.8 [13.8] years; 566 women [82.9%]); 72 were excluded. Of the 683 patients included, those assigned to the machine learning algorithm had significantly lower mean (SD) absolute error (control group, 59.3 [72] minutes; intervention group, 49.5 [66] minutes; difference, -9.8 minutes; P =.03) compared with the control group. Mean start-time delay for following cases (patient wait time in a presurgical area), dropped significantly: 62.4 minutes (from 70.2 minutes to 7.8 minutes) and 16.7 minutes (from 36.9 minutes to 20.2 minutes) for patients receiving colorectal and gynecology surgery, respectively. The overall mean (SD) reduction of wait time was 33.1 minutes per patient (from 49.4 minutes to 16.3 minutes per patient). Improved accuracy did not adversely inflate time between cases (surgeon wait time). There was marginal improvement (1.5 minutes, from a mean of 70.6 to 69.1 minutes) in time between the end of cases and start of to-follow cases using the predictive model, compared with the control group. Patients spent a mean of 25.2 fewer minutes in the facility before surgery (173.3 minutes vs 148.1 minutes), indicating a potential benefit vis-à-vis available resources for other patients before and after surgery. Conclusions and Relevance: Implementing machine learning-generated predictions for surgical case durations may improve case duration accuracy, presurgical resource use, and patient wait time, without increasing surgeon wait time between cases. Trial Registration: ClinicalTrials.gov Identifier: NCT03471377.  © 2021 American Medical Association. All rights reserved.},
	publisher = {American Medical Association},
	type = {Article},
	note = {Cited by: 47}
}

@CONFERENCE{Sapkota2024435,
	author = {Sapkota, Madhu Sudan and Doctor, Faiyaz and Herrera, Hugo and Kampouridis, Michael and Yang, Xinan},
	title = {Machine Learning to Predict Surgery Duration: Towards Implementing AI and Digital Twin for Effective Scheduling},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Medical Artificial Intelligence, MedAI 2024},
	pages = {435 – 440},
	doi = {10.1109/MedAI62885.2024.00064},
	abstract = {Traditional elective patients' surgical scheduling relies on plan-makers' subjective estimates or historical averages, leading to inefficiencies such as surgery cancellations or underutilisation of resources. Machine learning (M/L)-based predictive algorithms offer a promising solution with data-driven models to forecast surgical times, however, their application in NHS hospital settings remains limited. This study explores the implementation of multiple M/L algorithms for surgical time estimation for Trauma and Orthopaedics related procedures in an NHS Trust hospital. Results indicate that Neural Networks, along with ElasticNet regression, Gradient Boosting, and Bayesian Ridge regression models, demonstrate robust performance. Additionally, expansion to procedure specific models, built separately for each procedure shows promising results. This study contributes insights into the integration of M/L algorithms into healthcare digital resources, paving the way for enhanced surgical planning strategies. Future research will focus on integrating the predictive models into a comprehensive AI driven Digital Twin framework for simulation and optimisation-driven automated decision-making.  © 2024 IEEE.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	type = {Conference paper},
	note = {Cited by: 0}
}

@ARTICLE{Mao2023,
	author = {Mao, Chengsheng and Xu, Jie and Rasmussen, Luke and Li, Yikuan and Adekkanattu, Prakash and Pacheco, Jennifer and Bonakdarpour, Borna and Vassar, Robert and Shen, Li and Jiang, Guoqian and Wang, Fei and Pathak, Jyotishman and Luo, Yuan},
	title = {AD-BERT: Using pre-trained language model to predict the progression from mild cognitive impairment to Alzheimer's disease},
	year = {2023},
	journal = {Journal of Biomedical Informatics},
	volume = {144},
	doi = {10.1016/j.jbi.2023.104442},
	abstract = {Objective: We develop a deep learning framework based on the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model using unstructured clinical notes from electronic health records (EHRs) to predict the risk of disease progression from Mild Cognitive Impairment (MCI) to Alzheimer's Disease (AD). Methods: We identified 3657 patients diagnosed with MCI together with their progress notes from Northwestern Medicine Enterprise Data Warehouse (NMEDW) between 2000 and 2020. The progress notes no later than the first MCI diagnosis were used for the prediction. We first preprocessed the notes by deidentification, cleaning and splitting into sections, and then pre-trained a BERT model for AD (named AD-BERT) based on the publicly available Bio+Clinical BERT on the preprocessed notes. All sections of a patient were embedded into a vector representation by AD-BERT and then combined by global MaxPooling and a fully connected network to compute the probability of MCI-to-AD progression. For validation, we conducted a similar set of experiments on 2563 MCI patients identified at Weill Cornell Medicine (WCM) during the same timeframe. Results: Compared with the 7 baseline models, the AD-BERT model achieved the best performance on both datasets, with Area Under receiver operating characteristic Curve (AUC) of 0.849 and F1 score of 0.440 on NMEDW dataset, and AUC of 0.883 and F1 score of 0.680 on WCM dataset. Conclusion: The use of EHRs for AD-related research is promising, and AD-BERT shows superior predictive performance in modeling MCI-to-AD progression prediction. Our study demonstrates the utility of pre-trained language models and clinical notes in predicting MCI-to-AD progression, which could have important implications for improving early detection and intervention for AD. © 2023 Elsevier Inc.},
	publisher = {Academic Press Inc.},
	type = {Article},
	note = {Cited by: 25}
}

@ARTICLE{Shen2022,
	author = {Shen, Zitao and Schutte, Dalton and Yi, Yoonkwon and Bompelli, Anusha and Yu, Fang and Wang, Yanshan and Zhang, Rui},
	title = {Classifying the lifestyle status for Alzheimer’s disease from clinical notes using deep learning with weak supervision},
	year = {2022},
	journal = {BMC Medical Informatics and Decision Making},
	volume = {22},
	doi = {10.1186/s12911-022-01819-4},
	abstract = {Background: Since no effective therapies exist for Alzheimer’s disease (AD), prevention has become more critical through lifestyle status changes and interventions. Analyzing electronic health records (EHRs) of patients with AD can help us better understand lifestyle’s effect on AD. However, lifestyle information is typically stored in clinical narratives. Thus, the objective of the study was to compare different natural language processing (NLP) models on classifying the lifestyle statuses (e.g., physical activity and excessive diet) from clinical texts in English. Methods: Based on the collected concept unique identifiers (CUIs) associated with the lifestyle status, we extracted all related EHRs for patients with AD from the Clinical Data Repository (CDR) of the University of Minnesota (UMN). We automatically generated labels for the training data by using a rule-based NLP algorithm. We conducted weak supervision for pre-trained Bidirectional Encoder Representations from Transformers (BERT) models and three traditional machine learning models as baseline models on the weakly labeled training corpus. These models include the BERT base model, PubMedBERT (abstracts + full text), PubMedBERT (only abstracts), Unified Medical Language System (UMLS) BERT, Bio BERT, Bio-clinical BERT, logistic regression, support vector machine, and random forest. The rule-based model used for weak supervision was tested on the GSC for comparison. We performed two case studies: physical activity and excessive diet, in order to validate the effectiveness of BERT models in classifying lifestyle status for all models were evaluated and compared on the developed Gold Standard Corpus (GSC) on the two case studies. Results: The UMLS BERT model achieved the best performance for classifying status of physical activity, with its precision, recall, and F-1 scores of 0.93, 0.93, and 0.92, respectively. Regarding classifying excessive diet, the Bio-clinical BERT model showed the best performance with precision, recall, and F-1 scores of 0.93, 0.93, and 0.93, respectively. Conclusion: The proposed approach leveraging weak supervision could significantly increase the sample size, which is required for training the deep learning models. By comparing with the traditional machine learning models, the study also demonstrates the high performance of BERT models for classifying lifestyle status for Alzheimer’s disease in clinical notes. © 2022, The Author(s).},
	publisher = {BioMed Central Ltd},
	type = {Article},
	note = {Cited by: 16}
}

@ARTICLE{BenMiled2023,
	author = {Ben Miled, Zina and Dexter, Paul R. and Grout, Randall W. and Boustani, Malaz},
	title = {Feature engineering from medical notes: A case study of dementia detection},
	year = {2023},
	journal = {Heliyon},
	volume = {9},
	number = {3},
	doi = {10.1016/j.heliyon.2023.e14636},
	abstract = {Background and objectives: Medical notes are narratives that describe the health of the patient in free text format. These notes can be more informative than structured data such as the history of medications or disease conditions. They are routinely collected and can be used to evaluate the patient's risk for developing chronic diseases such as dementia. This study investigates different methodologies for transforming routine care notes into dementia risk classifiers and evaluates the generalizability of these classifiers to new patients and new health care institutions. Methods: The notes collected over the relevant history of the patient are lengthy. In this study, TF-ICF is used to select keywords with the highest discriminative ability between at risk dementia patients and healthy controls. The medical notes are then summarized in the form of occurrences of the selected keywords. Two different encodings of the summary are compared. The first encoding consists of the average of the vector embedding of each keyword occurrence as produced by the BERT or Clinical BERT pre-trained language models. The second encoding aggregates the keywords according to UMLS concepts and uses each concept as an exposure variable. For both encodings, misspellings of the selected keywords are also considered in an effort to improve the predictive performance of the classifiers. A neural network is developed over the first encoding and a gradient boosted trees model is applied to the second encoding. Patients from a single health care institution are used to develop all the classifiers which are then evaluated on held-out patients from the same health care institution as well as test patients from two other health care institutions. Results: The results indicate that it is possible to identify patients at risk for dementia one year ahead of the onset of the disease using medical notes with an AUC of 75% when a gradient boosted trees model is used in conjunction with exposure variables derived from UMLS concepts. However, this performance is not maintained with an embedded feature space and when the classifier is applied to patients from other health care institutions. Moreover, an analysis of the top predictors of the gradient boosted trees model indicates that different features inform the classification depending on whether or not spelling variants of the keywords are included. Conclusion: The present study demonstrates that medical notes can enable risk prediction models for complex chronic diseases such as dementia. However, additional research efforts are needed to improve the generalizability of these models. These efforts should take into consideration the length and localization of the medical notes; the availability of sufficient training data for each disease condition; and the variabilities resulting from different feature engineering techniques. © 2023 The Authors},
	publisher = {Elsevier Ltd},
	type = {Article},
	note = {Cited by: 3}
}

@ARTICLE{Jaotombo2023,
	author = {Jaotombo, Franck and Adorni, Luca and Ghattas, Badih and Boyer, Laurent},
	title = {Finding the best trade-off between performance and interpretability in predicting hospital length of stay using structured and unstructured data},
	year = {2023},
	journal = {PLoS ONE},
	volume = {18},
	number = {11 November},
	doi = {10.1371/journal.pone.0289795},
	abstract = {Objective This study aims to develop high-performing Machine Learning and Deep Learning models in predicting hospital length of stay (LOS) while enhancing interpretability. We compare performance and interpretability of models trained only on structured tabular data with models trained only on unstructured clinical text data, and on mixed data. Methods The structured data was used to train fourteen classical Machine Learning models including advanced ensemble trees, neural networks and k-nearest neighbors. The unstructured data was used to fine-tune a pre-trained Bio Clinical BERT Transformer Deep Learning model. The structured and unstructured data were then merged into a tabular dataset after vectorization of the clinical text and a dimensional reduction through Latent Dirichlet Allocation. The study used the free and publicly available Medical Information Mart for Intensive Care (MIMIC) III database, on the open AutoML Library AutoGluon. Performance is evaluated with respect to two types of random classifiers, used as baselines. Results The best model from structured data demonstrates high performance (ROC AUC = 0.944, PRC AUC = 0.655) with limited interpretability, where the most important predictors of prolonged LOS are the level of blood urea nitrogen and of platelets. The Transformer model displays a good but lower performance (ROC AUC = 0.842, PRC AUC = 0.375) with a richer array of interpretability by providing more specific in-hospital factors including procedures, conditions, and medical history. The best model trained on mixed data satisfies both a high level of performance (ROC AUC = 0.963, PRC AUC = 0.746) and a much larger scope in interpretability including pathologies of the intestine, the colon, and the blood; infectious diseases, respiratory problems, procedures involving sedation and intubation, and vascular surgery. Conclusions Our results outperform most of the state-of-the-art models in LOS prediction both in terms of performance and of interpretability. Data fusion between structured and unstructured text data may significantly improve performance and interpretability. Copyright: © 2023 Jaotombo et al.},
	publisher = {Public Library of Science},
	type = {Article},
	note = {Cited by: 7}
}

@ARTICLE{Daphne2025,
	author = {Daphne, S. and Rajam, V. Mary Anita and Hemanth, P. and Dinesh, Sundarrajan},
	title = {An Ensemble Patient Graph Framework for Predictive Modelling from Electronic Health Records and Medical Notes},
	year = {2025},
	journal = {Diagnostics},
	volume = {15},
	number = {6},
	doi = {10.3390/diagnostics15060756},
	abstract = {Objective: Electronic health records (EHRs) are becoming increasingly important in both academic research and business applications. Recent studies indicate that predictive tasks, such as heart failure detection, perform better when the geometric structure of EHR data, including the relationships between diagnoses and treatments, is considered. However, many EHRs lack essential structural information. This study aims to improve predictive accuracy in healthcare by constructing a Patient Knowledge Graph Ensemble Framework (PKGNN) to analyse ICU patient cohorts and predict mortality and hospital readmission outcomes. Methods: This study utilises a cohort of 42,671 patients from the MIMIC-IV dataset to build the PKGNN framework, which consists of three main components: (1) medical note extraction, (2) patient graph construction, and (3) prediction tasks. Advanced Natural Language Processing (NLP) models, including Clinical BERT, BioBERT, and BlueBERT, extract and integrate semantic representations from discharge summaries into a patient knowledge graph. This structured representation is then used to enhance predictive tasks. Results: Performance evaluations on the MIMIC-IV dataset indicate that the PKGNN framework outperforms state-of-the-art baseline models in predicting mortality and 30-day hospital readmission. A thorough framework analysis reveals that incorporating patient graph structures improves prediction accuracy. Furthermore, an ensemble model enhances risk prediction performance and identifies crucial clinical indicators. Conclusions: This study highlights the importance of leveraging structured knowledge graphs in EHR analysis to improve predictive modelling for critical healthcare outcomes. The PKGNN framework enhances the accuracy of mortality and readmission predictions by integrating advanced NLP techniques with patient graph structures. This work contributes to the literature by advancing knowledge graph-based EHR analysis strategies, ultimately supporting better clinical decision-making and risk assessment. © 2025 by the authors.},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	type = {Article},
	note = {Cited by: 0}
}

@ARTICLE{Henriksson2023,
	author = {Henriksson, Aron and Pawar, Yash and Hedberg, Pontus and Nauclér, Pontus},
	title = {Multimodal fine-tuning of clinical language models for predicting COVID-19 outcomes},
	year = {2023},
	journal = {Artificial Intelligence in Medicine},
	volume = {146},
	doi = {10.1016/j.artmed.2023.102695},
	abstract = {Clinical prediction models tend only to incorporate structured healthcare data, ignoring information recorded in other data modalities, including free-text clinical notes. Here, we demonstrate how multimodal models that effectively leverage both structured and unstructured data can be developed for predicting COVID-19 outcomes. The models are trained end-to-end using a technique we refer to as multimodal fine-tuning, whereby a pre-trained language model is updated based on both structured and unstructured data. The multimodal models are trained and evaluated using a multicenter cohort of COVID-19 patients encompassing all encounters at the emergency department of six hospitals. Experimental results show that multimodal models, leveraging the notion of multimodal fine-tuning and trained to predict (i) 30-day mortality, (ii) safe discharge and (iii) readmission, outperform unimodal models trained using only structured or unstructured healthcare data on all three outcomes. Sensitivity analyses are performed to better understand how well the multimodal models perform on different patient groups, while an ablation study is conducted to investigate the impact of different types of clinical notes on model performance. We argue that multimodal models that make effective use of routinely collected healthcare data to predict COVID-19 outcomes may facilitate patient management and contribute to the effective use of limited healthcare resources. © 2023 The Author(s)},
	publisher = {Elsevier B.V.},
	type = {Article},
	note = {Cited by: 6}
}

@ARTICLE{Mulyar20212108,
	author = {Mulyar, Andriy and Uzuner, Ozlem and Mcinnes, Bridget},
	title = {MT-clinical BERT: scaling clinical information extraction with multitask learning},
	year = {2021},
	journal = {Journal of the American Medical Informatics Association},
	volume = {28},
	number = {10},
	pages = {2108 – 2115},
	doi = {10.1093/jamia/ocab126},
	abstract = {Objective: Clinical notes contain an abundance of important, but not-readily accessible, information about patients. Systems that automatically extract this information rely on large amounts of training data of which there exists limited resources to create. Furthermore, they are developed disjointly, meaning that no information can be shared among task-specific systems. This bottleneck unnecessarily complicates practical application, reduces the performance capabilities of each individual solution, and associates the engineering debt of managing multiple information extraction systems. Materials and Methods: We address these challenges by developing Multitask-Clinical BERT: a single deep learning model that simultaneously performs 8 clinical tasks spanning entity extraction, personal health information identification, language entailment, and similarity by sharing representations among tasks. Results: We compare the performance of our multitasking information extraction system to state-of-the-art BERT sequential fine-tuning baselines. We observe a slight but consistent performance degradation in MT-Clinical BERT relative to sequential fine-tuning. Discussion: These results intuitively suggest that learning a general clinical text representation capable of supporting multiple tasks has the downside of losing the ability to exploit dataset or clinical note-specific properties when compared to a single, task-specific model. Conclusions: We find our single system performs competitively with all state-the-art task-specific systems while also benefiting from massive computational benefits at inference. © 2021 The Author(s).},
	publisher = {Oxford University Press},
	type = {Article},
	note = {Cited by: 34}
}

@ARTICLE{Vithanage2024158,
	author = {Vithanage, Dinithi and Yu, Ping and Wang, Lei and Deng, Chao},
	title = {Contextual Word Embedding for Biomedical Knowledge Extraction: a Rapid Review and Case Study},
	year = {2024},
	journal = {Journal of Healthcare Informatics Research},
	volume = {8},
	number = {1},
	pages = {158 – 179},
	doi = {10.1007/s41666-023-00157-y},
	abstract = {Recent advancements in natural language processing (NLP), particularly contextual word embedding models, have improved knowledge extraction from biomedical and healthcare texts. However, limited comprehensive research compares these models. This study conducts a scoping review and compares the performance of the major contextual word embedding models for biomedical knowledge extraction. From 26 articles identified from Scopus, PubMed, PubMed Central, and Google Scholar between 2017 and 2021, 18 notable contextual word embedding models were identified. These include ELMo, BERT, BioBERT, BlueBERT, CancerBERT, DDS-BERT, RuBERT, LABSE, EhrBERT, MedBERT, Clinical BERT, Clinical BioBERT, Discharge Summary BERT, Discharge Summary BioBERT, GPT, GPT-2, GPT-3, and GPT2-Bio-Pt. A case study compared the performance of six representative models—ELMo, BERT, BioBERT, BlueBERT, Clinical BioBERT, and GPT-3—across text classification, named entity recognition, and question answering. The evaluation utilized datasets comprising biomedical text from tweets, NCBI, PubMed, and clinical notes sourced from two electronic health record datasets. Performance metrics, including accuracy and F1 score, were used. The results of this case study reveal that BioBERT performs the best in analyzing biomedical text, while Clinical BioBERT excels in analyzing clinical notes. These findings offer crucial insights into word embedding models for researchers, practitioners, and stakeholders utilizing NLP in biomedical and clinical document analysis. © 2024, The Author(s), under exclusive licence to Springer Nature Switzerland AG.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	type = {Article},
	note = {Cited by: 5}
}

@ARTICLE{Gatto2022,
	author = {Gatto, Joseph and Seegmiller, Parker and Johnston, Garrett and Preum, Sarah Masud},
	title = {Identifying the Perceived Severity of Patient-Generated Telemedical Queries Regarding COVID: Developing and Evaluating a Transfer Learning–Based Solution},
	year = {2022},
	journal = {JMIR Medical Informatics},
	volume = {10},
	number = {9},
	doi = {10.2196/37770},
	abstract = {Background: Triage of textual telemedical queries is a safety-critical task for medical service providers with limited remote health resources. The prioritization of patient queries containing medically severe text is necessary to optimize resource usage and provide care to those with time-sensitive needs. Objective: We aim to evaluate the effectiveness of transfer learning solutions on the task of telemedical triage and provide a thorough error analysis, identifying telemedical queries that challenge state-of-the-art natural language processing (NLP) systems. Additionally, we aim to provide a publicly available telemedical query data set with labels for severity classification for telemedical triage of respiratory issues. Methods: We annotated 573 medical queries from 3 online health platforms: HealthTap, HealthcareMagic, and iCliniq. We then evaluated 6 transfer learning solutions utilizing various text-embedding strategies. Specifically, we first established a baseline using a lexical classification model with term frequency–inverse document frequency (TF-IDF) features. Next, we investigated the effectiveness of global vectors for text representation (GloVe), a pretrained word-embedding method. We evaluated the performance of GloVe embeddings in the context of support vector machines (SVMs), bidirectional long short-term memory (bi-LSTM) networks, and hierarchical attention networks (HANs). Finally, we evaluated the performance of contextual text embeddings using transformer-based architectures. Specifically, we evaluated bidirectional encoder representation from transformers (BERT), Bio+Clinical-BERT, and Sentence-BERT (SBERT) on the telemedical triage task. Results: We found that a simple lexical model achieved a mean F1 score of 0.865 (SD 0.048) on the telemedical triage task. GloVe-based models using SVMs, HANs, and bi-LSTMs achieved a 0.8-, 1.5-, and 2.1-point increase in the F1 score, respectively. Transformer-based models, such as BERT, Bio+Clinical-BERT, and SBERT, achieved a mean F1 score of 0.914 (SD 0.034), 0.904 (SD 0.041), and 0.917 (SD 0.037), respectively. The highest-performing model, SBERT, provided a statistically significant improvement compared to all GloVe-based and lexical baselines. However, no statistical significance was found when comparing transformer-based models. Furthermore, our error analysis revealed highly challenging query types, including those with complex negations, temporal relationships, and patient intents. Conclusions: We showed that state-of-the-art transfer learning techniques work well on the telemedical triage task, providing significant performance increase over lexical models. Additionally, we released a public telemedical triage data set using labeled questions from online medical question-and-answer (Q&A) platforms. Our analysis highlights various avenues for future works that explicitly model such query challenges. ©Joseph Gatto, Parker Seegmiller, Garrett Johnston, Sarah Masud Preum.},
	publisher = {JMIR Publications Inc.},
	type = {Article},
	note = {Cited by: 4}
}

@ARTICLE{Jiao20201885,
	author = {Jiao, York and Sharma, Anshuman and Abdallah, Arbi Ben and Maddox, Thomas M. and Kannampallil, Thomas},
	title = {Probabilistic forecasting of surgical case duration using machine learning: Model development and validation},
	year = {2020},
	journal = {Journal of the American Medical Informatics Association},
	volume = {27},
	number = {12},
	pages = {1885 – 1893},
	doi = {10.1093/jamia/ocaa140},
	abstract = {Objective: Accurate estimations of surgical case durations can lead to the cost-effective utilization of operating rooms. We developed a novel machine learning approach, using both structured and unstructured features as input, to predict a continuous probability distribution of surgical case durations. Materials and Methods: The data set consisted of 53 783 surgical cases performed over 4 years at a tertiary-care pediatric hospital. Features extracted included categorical (American Society of Anesthesiologists [ASA] Physical Status, inpatient status, day of week), continuous (scheduled surgery duration, patient age), and unstructured text (procedure name, surgical diagnosis) variables. A mixture density network (MDN) was trained and compared to multiple tree-based methods and a Bayesian statistical method. A continuous ranked probability score (CRPS), a generalized extension of mean absolute error, was the primary performance measure. Pinball loss (PL) was calculated to assess accuracy at specific quantiles. Performance measures were additionally evaluated on common and rare surgical procedures. Permutation feature importance was measured for the best performing model. Results: MDN had the best performance, with a CRPS of 18.1 minutes, compared to tree-based methods (19.5–22.1 minutes) and the Bayesian method (21.2 minutes). MDN had the best PL at all quantiles, and the best CRPS and PL for both common and rare procedures. Scheduled duration and procedure name were the most important features in the MDN. Conclusions: Using natural language processing of surgical descriptors, we demonstrated the use of ML approaches to predict the continuous probability distribution of surgical case durations. The more discerning forecast of the ML-based MDN approach affords opportunities for guiding intelligent schedule design and day-of-surgery operational decisions. © The Author(s) 2020.},
	publisher = {Oxford University Press},
	type = {Article},
	note = {Cited by: 35}
}

@ARTICLE{Adams2023,
	author = {Adams, T. and O'Sullivan, M. and Walker, C.},
	title = {Surgical procedure prediction using medical ontological information},
	year = {2023},
	journal = {Computer Methods and Programs in Biomedicine},
	volume = {235},
	doi = {10.1016/j.cmpb.2023.107541},
	abstract = {Background and Objective: Predicting the duration of surgical procedures is an important step in scheduling operating rooms. Many factors have been shown to influence the duration of a procedure, in this research we aim to use medical ontological information to improve the predictions. Methods: This paper presents two methods for incorporating the medical information about a surgical procedure into the prediction of the duration of the procedure. The first method uses the Systematised Nomenclature of Medicine Clinical Terms to relate different procedures to each other. The second uses simple text fragments. The relationships between types of procedures are included in a regression model for the procedure duration. These methods are applied to data from New Zealand healthcare facilities and the accuracy of the estimations of the durations is compared. In addition a simulation of scheduling the procedures in an operating room is performed. Results: It is shown that both of the methods provide an improvement in the prediction of procedure durations. When compared to a traditional categorical encoding, the ontological information provides an improvement in the continuous ranked probability scores of the prediction of procedure durations from 18.4 min to 17.1 min, and from 25.3 to 21.3 min for types of procedures that are not performed very often. Conclusions: Different methods for encoding medical ontological information in surgery procedure duration predictions are presented, and show an improvement over traditional models. The improvement in duration prediction is shown to improve the efficiency of scheduling in a simple simulation. © 2023},
	publisher = {Elsevier Ireland Ltd},
	type = {Article},
	note = {Cited by: 6}
}

@ARTICLE{Ramamurthi2025,
	author = {Ramamurthi, Adhitya and Neupane, Bhabishya and Deshpande, Priya and Hanson, Ryan and Brown, Kellie R. and Christians, Kathleen K. and Evans, Douglas B. and Kothari, Anai N.},
	title = {Development and validation of an artificial intelligence system for surgical case length prediction},
	year = {2025},
	journal = {Surgery (United States)},
	volume = {179},
	doi = {10.1016/j.surg.2024.09.051},
	abstract = {Background: Accurate case length estimation is a vital part of optimizing operating room use; however, significant inaccuracies exist with current solutions. The purpose of this study was to develop and validate an artificial intelligence system for improved surgical case length prediction by applying natural language processing and machine-learning methods. Methods: All inpatient elective surgical cases longer than 30 minutes completed between 2017 and 2023 at a single, quaternary care hospital were considered. Data were split into training, test, and hold-out validation for model training and testing. Linear regression, CategoricalBoost, and feed-forward neural network each were trained and used embeddings created by bidirectional encoder representations from transformers or a bidirectional encoder representations from transformers model pretrained on clinical text. The average root mean squared error and mean absolute error were calculated for each model. Results: A total of 125,493 cases were included. The highest performing model was the CategoricalBoost Regressor with bidirectional encoder representations from transformers model pretrained on clinical text embeddings (mean absolute error, 46.4 minutes), which was lower than the existing electronic health record estimates (120.0 minutes, P < 0.001). Accurate estimation of case length was defined as within ±20% of the actual case length with our model having 48% accuracy vs 17% accuracy for electronic health record–generated estimates. Conclusion: An artificial intelligence model for surgical case length estimation outperforms existing institutional electronic health record predictions. On average, the estimate improved by 62% and approximately 2.8× the number of cases were correctly estimated. This study shows the successful development of machine learning models using advanced natural language processing techniques for improved surgical case length prediction. © 2024 Elsevier Inc.},
	publisher = {Elsevier Inc.},
	type = {Article},
	note = {Cited by: 0}
}

@ARTICLE{Entezari2023,
	author = {Entezari, Bahar and Koucheki, Robert and Abbas, Aazad and Toor, Jay and Wolfstadt, Jesse I. and Ravi, Bheeshma and Whyne, Cari and Lex, Johnathan R.},
	title = {Improving Resource Utilization for Arthroplasty Care by Leveraging Machine Learning and Optimization: A Systematic Review},
	year = {2023},
	journal = {Arthroplasty Today},
	volume = {20},
	doi = {10.1016/j.artd.2023.101116},
	abstract = {Background: There is a growing demand for total joint arthroplasty (TJA) surgery. The applications of machine learning (ML), mathematical optimization, and computer simulation have the potential to improve efficiency of TJA care delivery through outcome prediction and surgical scheduling optimization, easing the burden on health-care systems. The purpose of this study was to evaluate strategies using advances in analytics and computational modeling that may improve planning and the overall efficiency of TJA care. Methods: A systematic review including MEDLINE, Embase, and IEEE Xplore databases was completed from inception to October 3, 2022, for identification of studies generating ML models for TJA length of stay, duration of surgery, and hospital readmission prediction. A scoping review of optimization strategies in elective surgical scheduling was also conducted. Results: Twenty studies were included for evaluating ML predictions and 17 in the scoping review of scheduling optimization. Among studies generating linear or logistic control models alongside ML models, only 1 found a control model to outperform its ML counterpart. Furthermore, neural networks performed superior to or at the same level as conventional ML models in all but 1 study. Implementation of mathematical and simulation strategies improved the optimization efficiency when compared to traditional scheduling methods at the operational level. Conclusions: High-performing predictive ML-based models have been developed for TJA, as have mathematical strategies for elective surgical scheduling optimization. By leveraging artificial intelligence for outcome prediction and surgical optimization, there exist greater opportunities for improved resource utilization and cost-savings in TJA than when using traditional modeling and scheduling methods. © 2023 The Authors},
	publisher = {Elsevier Inc.},
	type = {Article},
	note = {Cited by: 5}
}

